1) Create a github reposistory called i.e End-to-end-Machine-Learning-Project-with-MLflow where you can make it public, add .gitignore for python and select MIT license

2) Clone the reposistory in local and open it with vs code. Also Create new conda env i.e mlflow_project and activate it.

3) Create template.py file and we are creating this template.py file because we need lots of files and folders to manage the code. So that I do not need to create files and folders manually because script will automatically creates all of them.

4)Run template.py

5) .github has .gitkeep because we will be pushing to github repo for ci-cd pipeline using github workflows.

6) commit the changes to the github using=> git add . && git commit -m "folder structure added" && git push origin main

7) Create setup.py file where it will install the files and folder as local package. setup.py will look for __init__.py (constructor file) file and it will install it as local pacakges.

8) Install the packages using requirements.txt file using command => pip install -r requirements.txt

9) commit the changes to the github using=> git add . && git commit -m "requirements added" && git push origin main

10) Got to src/mlProject/__init__.py and add the code for logging. We are adding logging code in __init__.py so that it will be easy to import and we can ignore folders as the code or logic is written in  __init__.py file.

11) Write code in main.py for logging and test it. python main.py

12) Now to src/mlProject/utils/common.py It is created so that we can write all the common codes and reuse it whenever required. For example if you want to read yaml file you can write the function in utils and reuse it wherever required.

13) Create common.py file code 

14) Go to research/trials.ipynb and understand the working of ConfigBox and its functionality. Then understand about @ensure_annotations. ensure_annotations is useful when miss any datatype when passing the arguments.

15) Click on source controls on left hand side and type commit message and commit the code to github

16) Update ReadMe.md file to add workflows

17) Create 01_data_ingestion.ipynb file under research/01_data_ingestion.ipynb

18) Update the config/config.yaml and enter the required config details

19) add code to constants/__init__.py

20) Add the code to research/01_data_ingestion.ipynb for returning file path

21) Add key:val to schema.yaml & params.yaml

22) Add code from research/01_data_ingestion.ipynb to src/mlProject/entity/config_entity.py for DataIngestionConfig

23) Add code from research/01_data_ingestion.ipynb to src/mlProject/config/configuration.py for ConfigurationManager

24) Add src/mlProject/components/data_ingestion.py and add code to it

25) Add src/mlProject/pipeline/stage_01_data_ingestion.py and add code to it

26) Add code to main.py for data_ingestion

27) Click on source controls on left hand side and type commit message "data ingestion added" and commit the code to github

28) add artifacts in .gitignore and add the changes to github from source control

29) Add config code for data validation config/config.yaml

30) Add details to schema.yaml

Data Validation steps

31) Create research/02_data_validation.ipynb file and run it.

32) Add code from research/02_data_validation.ipynb to src/mlProject/entity/config_entity.py for DataValidation

33) Add code from research/02_data_validation.ipynb to src/mlProject/config/configuration.py for ConfigurationManager

34) Add src/mlProject/components/data_validation.py and add code to it

35) Add src/mlProject/pipeline/stage_02_data_validation.py and add code to it

36) Add code to main.py for data_ingestion

Data transformation

37) Add config for Data transformation part in config/config.yaml

38) Create research/03_data_transformation.ipynb file and run It

39) Add entity for data transformation in src/mlProject/entity/config_entity.py

40) Add configuration for data transformation in src/mlProject/config/configuration.py

41) Create src/mlProject/components/data_transformation.py in components

42) Create src/mlProject/pipeline/stage_03_data_transformation.py file

43) Add data_transformation logic in main.py

Model Training 

44) Create research/04_model_trainer.ipynb file and run It

45) Add config for model training part in config/config.yaml

46) Add entity for model training in src/mlProject/entity/config_entity.py

47) Add parameters for model in params.yaml

48) Add configuration for model training in src/mlProject/config/configuration.py

49) Create src/mlProject/components/model_trainer.py in components

50) Create src/mlProject/pipeline/stage_04_model_trainer.py file